import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_absolute_error

# Paths
descriptor_path = "magpie_descriptors.xlsx"
excel_path = "charge_discharge_pairs.xlsx"

# Load data
desc_df = pd.read_excel(descriptor_path)
pair_df = pd.read_excel(excel_path)
pair_df = pair_df[(pair_df["average_voltage"] >= -2) & (pair_df["average_voltage"] <= 7)]

# Clean descriptor data
desc_df = desc_df.dropna().drop_duplicates(subset=["material_id"])
desc_df.set_index("material_id", inplace=True)
desc_cols = [col for col in desc_df.columns if col != "material_id"]

# Merge charge and discharge descriptors
pair_df = pair_df.dropna(subset=["id_charge", "id_discharge", "average_voltage", "working_ion"])
pair_df = pair_df.merge(desc_df.add_prefix("chg_"), left_on="id_charge", right_index=True, how="inner")
pair_df = pair_df.merge(desc_df.add_prefix("dis_"), left_on="id_discharge", right_index=True, how="inner")

# Features and target
X = pair_df[[f"chg_{col}" for col in desc_cols] + [f"dis_{col}" for col in desc_cols]].values
y = pair_df["average_voltage"].values
stratify_labels = pair_df["working_ion"].astype(str).values

# Normalize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.1, random_state=42, stratify=stratify_labels
)

# DNN model
class SimpleDNN(nn.Module):
    def __init__(self, input_dim):
        super().__init__()
        self.net = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.ReLU(),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Linear(128, 32),
            nn.ReLU(),
            nn.Linear(32, 1)
        )

    def forward(self, x):
        return self.net(x).squeeze()

# Torch setup
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = SimpleDNN(input_dim=X.shape[1]).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)
loss_fn = nn.MSELoss()

# Convert to tensors
X_train_t = torch.tensor(X_train, dtype=torch.float32).to(device)
y_train_t = torch.tensor(y_train, dtype=torch.float32).to(device)
X_test_t = torch.tensor(X_test, dtype=torch.float32).to(device)
y_test_t = torch.tensor(y_test, dtype=torch.float32).to(device)

# Training loop
for epoch in range(1, 201):
    model.train()
    optimizer.zero_grad()
    pred = model(X_train_t)
    loss = loss_fn(pred, y_train_t)
    loss.backward()
    optimizer.step()

    if epoch % 50 == 0:
        model.eval()
        with torch.no_grad():
            test_pred = model(X_test_t).cpu().numpy()
        r2 = r2_score(y_test, test_pred)
        print(f"Epoch {epoch:03d} | Train MSE: {loss.item():.4f} | Test RÂ²: {r2:.4f}")

# Final evaluation
model.eval()
with torch.no_grad():
    final_pred = model(X_test_t).cpu().numpy()

print("\nFinal Evaluation:")
print(f"RÂ²  = {r2_score(y_test, final_pred):.4f}")
print(f"MAE = {mean_absolute_error(y_test, final_pred):.4f}")
